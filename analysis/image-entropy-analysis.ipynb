{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os.path import exists, join, basename\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from json import load, dump\n",
    "from sys import argv\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from PIL import Image, ImageDraw\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import tarfile\n",
    "import zipfile\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plt.style.use('ggplot')\n",
    "# plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_EMB_PATH = \"/nvmescratch/diffusiondb/prompt-emb/prompt-emb.npz\"\n",
    "IMAGE_EMB_DIR = \"/nvmescratch/diffusiondb/img-emb\"\n",
    "PARQUET_PATH = \"/nvmescratch/diffusiondb/metadata.parquet\"\n",
    "\n",
    "ZIP_DIR1 = \"/project/diffusiondb-hugging/diffusiondb-large-part-1/\"\n",
    "ZIP_DIR2 = \"/project/diffusiondb-hugging/diffusiondb-large-part-2/\"\n",
    "\n",
    "WORK_DIR = \"/nvmescratch/diffusiondb/\"\n",
    "WORKING_IMAGE_DIR = \"/nvmescratch/diffusiondb/images/\"\n",
    "REMOTE_IMAGE_DIR = '/project/diffusiondb/images/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_parquet(\n",
    "    PARQUET_PATH,\n",
    "    columns=[\n",
    "        \"image_name\",\n",
    "        \"part_id\",\n",
    "        \"prompt\",\n",
    "        \"cfg\",\n",
    "        \"step\",\n",
    "        \"sampler\",\n",
    "        \"width\",\n",
    "        \"height\",\n",
    "        \"image_nsfw\",\n",
    "    ],\n",
    ")\n",
    "print(metadata_df.shape)\n",
    "metadata_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_part = {}\n",
    "name_to_index = {}\n",
    "for i in tqdm(range(0, len(metadata_df))):\n",
    "    name_to_part[metadata_df['image_name'][i]] = metadata_df['part_id'][i]\n",
    "    name_to_index[metadata_df['image_name'][i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read all entropies\n",
    "# image_entropies = {}\n",
    "\n",
    "# for f in tqdm(glob(join(WORK_DIR, 'entropy-pickles', '*.pkl'))):\n",
    "#     cur_dict = pickle.load(open(f, 'rb'))\n",
    "#     for name in cur_dict:\n",
    "#         image_entropies[name] = cur_dict[name]\n",
    "        \n",
    "# pickle.dump(image_entropies, open('./outputs/image_entropies.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_entropies = pickle.load(open('./outputs/image_entropies.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies = []\n",
    "\n",
    "for k in image_entropies:\n",
    "    entropies.append(image_entropies[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# plt.title('Image Entropy Distribution (14M)')\n",
    "# plt.hist(entropies, bins=100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a gausian distribution\n",
    "mean, std = norm.fit(entropies)\n",
    "\n",
    "sorted_pairs = []\n",
    "LOW_BAR = mean - 9 * std\n",
    "print(mean, std, LOW_BAR)\n",
    "\n",
    "for k in tqdm(image_entropies):\n",
    "    if image_entropies[k] < LOW_BAR:\n",
    "        sorted_pairs.append([k, image_entropies[k]])\n",
    "        \n",
    "sorted_pairs.sort(key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_pairs = []\n",
    "\n",
    "for p in tqdm(sorted_pairs):\n",
    "    # Check parameters\n",
    "    cur_i = name_to_index[p[0]]\n",
    "    cfg = metadata_df['cfg'][cur_i]\n",
    "    sampler = metadata_df['sampler'][cur_i]\n",
    "    step = metadata_df['step'][cur_i]\n",
    "    nsfw = metadata_df['image_nsfw'][cur_i]\n",
    "    width = metadata_df['width'][cur_i]\n",
    "    height = metadata_df['height'][cur_i]\n",
    "    nsfw = metadata_df['image_nsfw'][cur_i]\n",
    "    prompt = metadata_df['prompt'][cur_i]\n",
    "    \n",
    "    # if cfg > 1:\n",
    "    if nsfw < 2 and abs(cfg - 7) < 5 and min(width, height) >= 512 and step > 10:\n",
    "        new_p = {\n",
    "            'name': p[0],\n",
    "            'index': cur_i,\n",
    "            'entropy': p[1],\n",
    "            'cfg': cfg,\n",
    "            'sampler': sampler,\n",
    "            'step': step,\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'nsfw': nsfw,\n",
    "            'prompt': prompt\n",
    "        }\n",
    "        low_pairs.append(new_p)\n",
    "        \n",
    "print(len(low_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(name_to_part, name, existing_part_ids):\n",
    "    \"\"\"\n",
    "    Get the path of an image by its name.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find the part id of this image\n",
    "    part_id = name_to_part[name]\n",
    "    \n",
    "    if part_id in existing_part_ids:\n",
    "        image_path = join(REMOTE_IMAGE_DIR, f'part-{part_id:06}', name)\n",
    "        return image_path\n",
    "    \n",
    "    # Need to download the image's zip file first\n",
    "    else:\n",
    "        cur_zip = join(WORK_DIR, f\"part-{part_id:06}.zip\")\n",
    "        cur_img_dir = join(WORKING_IMAGE_DIR, f\"part-{part_id:06}\")\n",
    "\n",
    "        if not exists(cur_img_dir):\n",
    "            # Download and extract the zip file\n",
    "            if part_id > 100000:\n",
    "                shutil.copyfile(\n",
    "                    join(ZIP_DIR2, f\"part-{part_id:06}.zip\"),\n",
    "                    cur_zip,\n",
    "                )\n",
    "            else:\n",
    "                shutil.copyfile(\n",
    "                    join(ZIP_DIR1, f\"part-{part_id:06}.zip\"),\n",
    "                    cur_zip,\n",
    "                )\n",
    "\n",
    "            shutil.unpack_archive(cur_zip, cur_img_dir)\n",
    "            \n",
    "        image_path = join(WORKING_IMAGE_DIR, f'part-{part_id:06}', name)\n",
    "        \n",
    "    \n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_low_pairs = []\n",
    "added_prompts = set()\n",
    "for p in low_pairs:\n",
    "    if p['prompt'] not in added_prompts:\n",
    "        added_prompts.add(p['prompt'])\n",
    "        unique_low_pairs.append(p)\n",
    "        \n",
    "len(unique_low_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dsiplay these bad images\n",
    "folders = glob(\"/project/diffusiondb/images/*\")\n",
    "existing_part_ids = set(\n",
    "    [int(re.sub(r\".*part-(\\d+)\", r\"\\1\", f)) for f in folders if \"json\" not in f]\n",
    ")\n",
    "\n",
    "shutil.rmtree(join(WORKING_IMAGE_DIR, 'bad-images'))\n",
    "os.makedirs(join(WORKING_IMAGE_DIR, 'bad-images'))\n",
    "\n",
    "# Copy low distance images into one folder\n",
    "random_indexes = np.random.choice(len(unique_low_pairs), len(unique_low_pairs), replace=False)\n",
    "count_limit = 100\n",
    "visited_prompts = set()\n",
    "\n",
    "i = 0\n",
    "with tqdm(total=count_limit) as pbar:\n",
    "    while i < count_limit:\n",
    "        p = unique_low_pairs[random_indexes[i]]\n",
    "\n",
    "        cur_path = get_image_path(name_to_part, p['name'], existing_part_ids)\n",
    "        local_path = join(WORKING_IMAGE_DIR, 'bad-images', basename(cur_path))\\\n",
    "\n",
    "        if not exists(local_path):\n",
    "            shutil.copyfile(cur_path, local_path)\n",
    "            \n",
    "        img = Image.open(local_path)\n",
    "        img.thumbnail((300, 300), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        prompt = p['prompt']\n",
    "        \n",
    "        # display(img)\n",
    "        # print(p)\n",
    "        # i += 1\n",
    "\n",
    "        try:\n",
    "            canvas = ImageDraw.Draw(img)\n",
    "            canvas.text((10, 5), prompt[:40], fill=(255, 0, 0))\n",
    "            \n",
    "            if len(prompt) > 40:\n",
    "                canvas.text((10, 15), prompt[40:80], fill=(255, 0, 0))\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        img.save(local_path)\n",
    "        i += 1\n",
    "        pbar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9758838403ef5c64e3388c7f7eb0622abdec8769e35829ff20981977cccefff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
