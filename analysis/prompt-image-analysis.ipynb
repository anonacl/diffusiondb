{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os.path import exists, join, basename\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from json import load, dump\n",
    "from sys import argv\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "from PIL import Image, ImageDraw\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import tarfile\n",
    "import zipfile\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plt.style.use('ggplot')\n",
    "# plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_EMB_PATH = \"/nvmescratch/diffusiondb/prompt-emb/prompt-emb.npz\"\n",
    "IMAGE_EMB_DIR = \"/nvmescratch/diffusiondb/img-emb\"\n",
    "PARQUET_PATH = \"/nvmescratch/diffusiondb/metadata.parquet\"\n",
    "\n",
    "ZIP_DIR1 = \"/project/diffusiondb-hugging/diffusiondb-large-part-1/\"\n",
    "ZIP_DIR2 = \"/project/diffusiondb-hugging/diffusiondb-large-part-2/\"\n",
    "\n",
    "WORK_DIR = \"/nvmescratch/diffusiondb/temp/\"\n",
    "WORKING_IMAGE_DIR = \"/nvmescratch/diffusiondb/images/\"\n",
    "REMOTE_IMAGE_DIR = '/project/diffusiondb/images/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_parquet(PARQUET_PATH, columns=['image_name', 'prompt'])\n",
    "print(metadata_df.shape)\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a image name -> index dictionary for faster query\n",
    "image_name_dict = {}\n",
    "for i in range(0, metadata_df.shape[0]):\n",
    "    image_name_dict[metadata_df['image_name'][i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prompt embedding\n",
    "prompt_embs_data = np.load(PROMPT_EMB_PATH)\n",
    "prompts = prompt_embs_data['prompts']\n",
    "prompts_emb = prompt_embs_data['emb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt -> index dictionary for faster query\n",
    "prompt_dict = {}\n",
    "for i in range(0, len(prompts)):\n",
    "    prompt_dict[prompts[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(part_id):\n",
    "    errors = []\n",
    "    distances = []\n",
    "    \n",
    "    # Load image embedding\n",
    "    try:\n",
    "        image_emb_data = np.load(join(IMAGE_EMB_DIR, f'part-{part_id:06}-image-emb.npz'))\n",
    "        image_names = image_emb_data['images_name']\n",
    "        image_emb = image_emb_data['images_emb']\n",
    "    \n",
    "    except:\n",
    "        print('Major error')\n",
    "        errors.append([part_id, '', -1])\n",
    "        return distances, errors\n",
    "    \n",
    "\n",
    "    for (i, name) in enumerate(image_names):\n",
    "        cur_image_emb = image_emb[i, :]\n",
    "        \n",
    "        # Identify the prompt's embedding\n",
    "        try:\n",
    "            cur_prompt = metadata_df['prompt'][image_name_dict[name]]\n",
    "            cur_prompt_index = prompt_dict[cur_prompt]\n",
    "            cur_prompt_emb = prompts_emb[cur_prompt_index, :]\n",
    "            \n",
    "            distances.append([\n",
    "                name,\n",
    "                cur_prompt_index,\n",
    "                cosine(cur_image_emb, cur_prompt_emb),\n",
    "            ])\n",
    "            \n",
    "        except KeyError:\n",
    "            errors.append([part_id, name, -1])\n",
    "    \n",
    "    return distances, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "errors = []\n",
    "\n",
    "for part_id in tqdm(range(1, 14001)):\n",
    "    local_distances, local_errors = compute_distance(part_id)\n",
    "    distances.extend(local_distances)\n",
    "    errors.extend(local_errors)\n",
    "\n",
    "    # Save the progress\n",
    "    if part_id % 5000 == 0:\n",
    "        pickle.dump(\n",
    "            {\"distances\": distances, \"errors\": errors},\n",
    "            open(f\"./image_prompt_distance_{part_id:06}.pkl\", 'wb'),\n",
    "        )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Distance Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_parquet(PARQUET_PATH, columns=['image_name', 'part_id', 'prompt', 'cfg', 'step', 'sampler'])\n",
    "print(metadata_df.shape)\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prompt embedding\n",
    "prompt_embs_data = np.load(PROMPT_EMB_PATH)\n",
    "prompts = prompt_embs_data['prompts']\n",
    "prompts_emb = prompt_embs_data['emb']\n",
    "prompts_set = set(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_part = {}\n",
    "name_to_index = {}\n",
    "\n",
    "for i in tqdm(range(0, len(metadata_df))):\n",
    "    name_to_part[metadata_df['image_name'][i]] = metadata_df['part_id'][i]\n",
    "    name_to_index[metadata_df['image_name'][i]] = i\n",
    "\n",
    "image_prompt_distance_data = pickle.load(\n",
    "    open(f\"./image_prompt_distance.pkl\", 'rb')\n",
    ")\n",
    "\n",
    "distances = image_prompt_distance_data['distances']\n",
    "errors = image_prompt_distance_data['errors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a prompt -> index dictionary for faster query\n",
    "# prompt_dict = {}\n",
    "# for i in range(0, len(prompts)):\n",
    "#     prompt_dict[prompts[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prev_prompts_set = set(prompts)\n",
    "# no_emb_prompts = set()\n",
    "\n",
    "# for error_prompt in tqdm(error_prompts):\n",
    "#     if error_prompt.lower() not in prev_prompts_set:\n",
    "#         no_emb_prompts.add(error_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(no_emb_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute CLIP embedding for these no emb prompts\n",
    "# import torch\n",
    "# from sentence_transformers import SentenceTransformer, util\n",
    "# from transformers import CLIPTokenizer\n",
    "\n",
    "# print(torch.cuda.device_count(), \"GPUs\")\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)\n",
    "\n",
    "# # Load CLIP model\n",
    "# model = SentenceTransformer(\"clip-ViT-L-14\")\n",
    "\n",
    "# print(\"Initial # of prompts:\", len(no_emb_prompts))\n",
    "\n",
    "# # Make all prompts lower case and only use unique prompts\n",
    "# working_prompts = [p.lower() for p in no_emb_prompts]\n",
    "# working_prompts = set(working_prompts)\n",
    "# working_prompts = list(working_prompts)\n",
    "# print(\"Unique # of prompts:\", len(working_prompts))\n",
    "\n",
    "# tokenizer = model._first_module().processor.tokenizer\n",
    "\n",
    "\n",
    "# def truncate_sentence(sentence, tokenizer):\n",
    "#     \"\"\"\n",
    "#     Truncate a sentence to fit the CLIP max token limit (77 tokens including the\n",
    "#     starting and ending tokens).\n",
    "#     Args:\n",
    "#         sentence(string): The sentence to truncate.\n",
    "#         tokenizer(CLIPTokenizer): Rretrained CLIP tokenizer.\n",
    "#     \"\"\"\n",
    "\n",
    "#     cur_sentence = sentence\n",
    "#     tokens = tokenizer.encode(cur_sentence)\n",
    "\n",
    "#     if len(tokens) > 77:\n",
    "#         # Skip the starting token, only include 75 tokens\n",
    "#         truncated_tokens = tokens[1:76]\n",
    "#         cur_sentence = tokenizer.decode(truncated_tokens)\n",
    "\n",
    "#         # Recursive call here, because the encode(decode()) can have different\n",
    "#         # result\n",
    "#         return truncate_sentence(cur_sentence, tokenizer)\n",
    "\n",
    "#     else:\n",
    "#         return cur_sentence\n",
    "\n",
    "\n",
    "# truncated_prompts = []\n",
    "# for p in tqdm(working_prompts):\n",
    "#     truncated_prompts.append(truncate_sentence(p, tokenizer))\n",
    "\n",
    "# # Encode prompts\n",
    "# working_prompt_emb = model.encode(\n",
    "#     truncated_prompts, device=device, show_progress_bar=True, batch_size=512\n",
    "# )\n",
    "\n",
    "# # Save the embedding\n",
    "# print(working_prompt_emb.shape)\n",
    "\n",
    "# # np.savez_compressed(\n",
    "# #     join(PROMPT_EMB_DIR, \"prompt-emb.npz\"),\n",
    "# #     prompts=prompts,\n",
    "# #     emb=prompt_emb,\n",
    "# # )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Less-alignment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_parquet(\n",
    "    PARQUET_PATH,\n",
    "    columns=[\n",
    "        \"image_name\",\n",
    "        \"part_id\",\n",
    "        \"prompt\",\n",
    "        \"cfg\",\n",
    "        \"step\",\n",
    "        \"sampler\",\n",
    "        \"width\",\n",
    "        \"height\",\n",
    "        \"image_nsfw\",\n",
    "    ],\n",
    ")\n",
    "print(metadata_df.shape)\n",
    "metadata_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_part = {}\n",
    "name_to_index = {}\n",
    "for i in tqdm(range(0, len(metadata_df))):\n",
    "    name_to_part[metadata_df['image_name'][i]] = metadata_df['part_id'][i]\n",
    "    name_to_index[metadata_df['image_name'][i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prompt_distance_data = pickle.load(\n",
    "    open(f\"./image_prompt_distance_all.pkl\", 'rb')\n",
    ")\n",
    "\n",
    "distances = image_prompt_distance_data['distances']\n",
    "errors = image_prompt_distance_data['errors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance tuple: (name, prompt index, cosine, l1, l2, l-infinity)\n",
    "distance_tuples = {\n",
    "    'Cosine': 2,\n",
    "    'L1': 3,\n",
    "    'L2': 4,\n",
    "    'L-infinity': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in distance_tuples:\n",
    "\n",
    "k = 'Cosine'\n",
    "distance_scores = [p[distance_tuples[k]] for p in distances]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.grid(alpha=0.2)\n",
    "plt.hist(distance_scores, bins=100, edgecolor='white', linewidth=0.5, alpha=0.9)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel(\"Number of tokens in prompt\", fontsize=16)\n",
    "plt.title(f'Distribution of the prompt/image CLIP {k} distance', fontsize=18)\n",
    "plt.savefig(\"plots/cosine-dist.pdf\", bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plt.clf()\n",
    "# plt.cla()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(name_to_part, name, existing_part_ids):\n",
    "    \"\"\"\n",
    "    Get the path of an image by its name.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find the part id of this image\n",
    "    part_id = name_to_part[name]\n",
    "    \n",
    "    if part_id in existing_part_ids:\n",
    "        image_path = join(REMOTE_IMAGE_DIR, f'part-{part_id:06}', name)\n",
    "        return image_path\n",
    "    \n",
    "    # Need to download the image's zip file first\n",
    "    else:\n",
    "        cur_zip = join(WORK_DIR, f\"part-{part_id:06}.zip\")\n",
    "        cur_img_dir = join(WORKING_IMAGE_DIR, f\"part-{part_id:06}\")\n",
    "\n",
    "        if not exists(cur_img_dir):\n",
    "            # Download and extract the zip file\n",
    "            if part_id > 100000:\n",
    "                shutil.copyfile(\n",
    "                    join(ZIP_DIR2, f\"part-{part_id:06}.zip\"),\n",
    "                    cur_zip,\n",
    "                )\n",
    "            else:\n",
    "                shutil.copyfile(\n",
    "                    join(ZIP_DIR1, f\"part-{part_id:06}.zip\"),\n",
    "                    cur_zip,\n",
    "                )\n",
    "\n",
    "            shutil.unpack_archive(cur_zip, cur_img_dir)\n",
    "            \n",
    "        image_path = join(WORKING_IMAGE_DIR, f'part-{part_id:06}', name)\n",
    "        \n",
    "    \n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance_method = 'Cosine'\n",
    "# distance_i = distance_tuples[distance_method]\n",
    "# sorted_pairs = sorted(distances, key=lambda x: x[distance_i], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit a gausian distribution\n",
    "# mean, std = norm.fit([p[distance_i] for p in distances])\n",
    "# print(mean, std)\n",
    "\n",
    "# low_pairs = []\n",
    "# HIGH_BAR = mean + 6 * std\n",
    "\n",
    "# for p in sorted_pairs:\n",
    "#     if p[distance_i] > HIGH_BAR:\n",
    "#         low_pairs.append(p)\n",
    "        \n",
    "#     if p[distance_i] < HIGH_BAR:\n",
    "#         break\n",
    "    \n",
    "# print(HIGH_BAR, len(low_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate images from these pairs into bad-images\n",
    "# folders = glob(\"/project/diffusiondb/images/*\")\n",
    "# existing_part_ids = set(\n",
    "#     [int(re.sub(r\".*part-(\\d+)\", r\"\\1\", f)) for f in folders if \"json\" not in f]\n",
    "# )\n",
    "\n",
    "# shutil.rmtree(join(WORKING_IMAGE_DIR, 'bad-images'))\n",
    "# os.makedirs(join(WORKING_IMAGE_DIR, 'bad-images'))\n",
    "\n",
    "# # Copy low distance images into one folder\n",
    "# for p in tqdm(low_pairs[:100]):\n",
    "#     cur_path = get_image_path(name_to_part, p[0], existing_part_ids)\n",
    "#     local_path = join(WORKING_IMAGE_DIR, 'bad-images', basename(cur_path))\\\n",
    "\n",
    "#     if not exists(local_path):\n",
    "#         shutil.copyfile(cur_path, local_path)\n",
    "        \n",
    "#     img = Image.open(local_path)\n",
    "#     img.thumbnail((200, 200), Image.Resampling.LANCZOS)\n",
    "    \n",
    "#     df_index = name_to_index[p[0]]\n",
    "#     prompt = metadata_df['prompt'][df_index]\n",
    "    \n",
    "#     display(img)\n",
    "#     print(prompt)\n",
    "\n",
    "#     # try:\n",
    "#     #     canvas = ImageDraw.Draw(img)\n",
    "#     #     canvas.text((10, 5), prompt[:40], fill=(255, 0, 0))\n",
    "        \n",
    "#     #     if len(prompt) > 40:\n",
    "#     #         canvas.text((10, 15), prompt[40:80], fill=(255, 0, 0))\n",
    "            \n",
    "#     # except:\n",
    "#     #     pass\n",
    "    \n",
    "#     # img.save(local_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to focus on misalignment examples where the `cfg_scale` is at least positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_method = 'Cosine'\n",
    "distance_i = distance_tuples[distance_method]\n",
    "sorted_pairs = sorted(distances, key=lambda x: x[distance_i], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a gausian distribution\n",
    "mean, std = norm.fit([p[distance_i] for p in distances])\n",
    "print(mean, std)\n",
    "\n",
    "low_pairs = []\n",
    "HIGH_BAR = mean + 4 * std\n",
    "\n",
    "for p in sorted_pairs:\n",
    "    if p[distance_i] > HIGH_BAR:\n",
    "        # Check it's cfg score\n",
    "        cur_i = name_to_index[p[0]]\n",
    "        cfg = metadata_df['cfg'][cur_i]\n",
    "        sampler = metadata_df['sampler'][cur_i]\n",
    "        step = metadata_df['step'][cur_i]\n",
    "        nsfw = metadata_df['image_nsfw'][cur_i]\n",
    "        width = metadata_df['width'][cur_i]\n",
    "        height = metadata_df['height'][cur_i]\n",
    "        nsfw = metadata_df['image_nsfw'][cur_i]\n",
    "        \n",
    "        # if cfg > 1:\n",
    "        if nsfw < 2:\n",
    "            new_p = {\n",
    "                'name': p[0],\n",
    "                'index': p[1],\n",
    "                'Cosine': p[2],\n",
    "                'L1': p[3],\n",
    "                'L2': p[4],\n",
    "                'L-infinity': p[5],\n",
    "                'cfg': cfg,\n",
    "                'sampler': sampler,\n",
    "                'step': step,\n",
    "                'width': width,\n",
    "                'height': height,\n",
    "                'nsfw': nsfw\n",
    "            }\n",
    "            low_pairs.append(new_p)\n",
    "        \n",
    "    if p[distance_i] < HIGH_BAR:\n",
    "        break\n",
    "    \n",
    "print(HIGH_BAR, len(low_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chi-square test on the sampler distribution\n",
    "\n",
    "# samplers = [p['sampler'] for p in low_pairs]\n",
    "# counter_cur_samplers = Counter(samplers)\n",
    "\n",
    "# f_obs = [0 for _ in range(9)]\n",
    "# for k in counter_cur_samplers:\n",
    "#     f_obs[k - 1] = counter_cur_samplers[k]\n",
    "    \n",
    "# counter_all_samplers = Counter(metadata_df['sampler'])\n",
    "# f_exp = [0 for _ in range(9)]\n",
    "# for k in counter_all_samplers:\n",
    "#     f_exp[k - 1] = len(samplers) * (counter_all_samplers[k] / len(metadata_df))\n",
    "    \n",
    "# results = stats.chisquare(f_obs=f_obs, f_exp=f_exp)\n",
    "# results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check `step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps = [p['step'] for p in low_pairs if p['sampler'] == 8 and p['nsfw'] < 2]\n",
    "\n",
    "# plt.title('Step distribution of 4 sigma away images')\n",
    "# plt.hist(steps, bins=50)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lengths = [min(p['height'], p['width']) for p in low_pairs if p['sampler'] == 8 and p['nsfw'] < 2]\n",
    "\n",
    "# plt.title('Min(height, width) distribution of 4 sigma away images')\n",
    "# plt.hist(lengths, bins=50)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression to test these variables\n",
    "\n",
    "Treat bad image as a binary variable, and test the correlation with all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import linear_model\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the y variable\n",
    "# ys = [0 for _ in range(len(metadata_df))]\n",
    "\n",
    "# for p in low_pairs:\n",
    "#     ys[p['index']] = p['Cosine']\n",
    "    \n",
    "# # Create the x matrix\n",
    "\n",
    "# # cfg, step, sampler, min(width, height)\n",
    "# ols_df_dict = {\n",
    "#     'y': ys,\n",
    "#     'cfg': metadata_df['cfg'],\n",
    "#     'step': metadata_df['step'],\n",
    "#     'sampler': metadata_df['sampler'],\n",
    "#     'length':  np.min(np.array([metadata_df['width'].to_numpy(), metadata_df['height'].to_numpy()]), axis=0)\n",
    "# }\n",
    "# ols_df = pd.DataFrame.from_dict(ols_df_dict).dropna()\n",
    "# ols_df = ols_df[ols_df['cfg'] < 1e10]\n",
    "# print(ols_df.shape)\n",
    "# ols_df.head()\n",
    "\n",
    "# model = smf.ols(formula=\"y ~ cfg + step + C(sampler) + length\", data=ols_df).fit(maxiter=100)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a logistic regression \n",
    "# ys = [0 for _ in range(len(metadata_df))]\n",
    "\n",
    "# for p in low_pairs:\n",
    "#     ys[p['index']] = 1\n",
    "    \n",
    "# # Create the x matrix\n",
    "\n",
    "# # cfg, step, sampler, min(width, height)\n",
    "# ols_df_dict = {\n",
    "#     'y': ys,\n",
    "#     'cfg': metadata_df['cfg'],\n",
    "#     'step': metadata_df['step'],\n",
    "#     'sampler': metadata_df['sampler'],\n",
    "#     # 'length':  np.min(np.array([metadata_df['width'].to_numpy(), metadata_df['height'].to_numpy()]), axis=0)\n",
    "#     'width':  metadata_df['width'],\n",
    "#     'height':  metadata_df['height'],\n",
    "# }\n",
    "# ols_df = pd.DataFrame.from_dict(ols_df_dict).dropna()\n",
    "# ols_df = ols_df[ols_df['cfg'] < 1000]\n",
    "# ols_df = ols_df[ols_df['cfg'] > -1000]\n",
    "# print(ols_df.shape)\n",
    "# ols_df.head()\n",
    "\n",
    "# pos_df = ols_df[ols_df['y'] == 1]\n",
    "# neg_df = ols_df[ols_df['y'] == 0]\n",
    "\n",
    "# sampled_df = pd.concat([pos_df, neg_df.sample(pos_df.shape[0] * 10, replace=False)])\n",
    "# sampled_df = pd.concat([pos_df, neg_df])\n",
    "\n",
    "# scaler = StandardScaler().fit(sampled_df)\n",
    "# result = scaler.transform(sampled_df)\n",
    "\n",
    "# normed_df = pd.DataFrame({\n",
    "#     'y': sampled_df['y'],\n",
    "#     'cfg': result[:, 1],\n",
    "#     'step': result[:, 2],\n",
    "#     'sampler': sampled_df['sampler'],\n",
    "#     'length': result[:, 4],\n",
    "# })\n",
    "\n",
    "# # model = smf.logit(formula=\"y ~ cfg + step + C(sampler) + length\", data=ols_df).fit(method='nm', maxiter=600)\n",
    "# model = smf.logit(formula=\"y ~ cfg + step + C(sampler) + width + height\", data=ols_df).fit(method='nm', maxiter=600)\n",
    "# model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Bad Images after Controlling Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_method = 'Cosine'\n",
    "distance_i = distance_tuples[distance_method]\n",
    "sorted_pairs = sorted(distances, key=lambda x: x[distance_i], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a gausian distribution\n",
    "mean, std = norm.fit([p[distance_i] for p in distances])\n",
    "print(mean, std)\n",
    "\n",
    "low_pairs = []\n",
    "HIGH_BAR = mean + 4 * std\n",
    "\n",
    "for p in sorted_pairs:\n",
    "    if p[distance_i] > HIGH_BAR:\n",
    "        cur_i = name_to_index[p[0]]\n",
    "        cfg = metadata_df['cfg'][cur_i]\n",
    "        sampler = metadata_df['sampler'][cur_i]\n",
    "        step = metadata_df['step'][cur_i]\n",
    "        nsfw = metadata_df['image_nsfw'][cur_i]\n",
    "        width = metadata_df['width'][cur_i]\n",
    "        height = metadata_df['height'][cur_i]\n",
    "        nsfw = metadata_df['image_nsfw'][cur_i]\n",
    "        prompt = metadata_df['prompt'][cur_i]\n",
    "        \n",
    "        if nsfw < 2 and abs(cfg - 7) < 5 and sampler == 8 and min(width, height) >= 512 and step > 10:\n",
    "            new_p = {\n",
    "                'name': p[0],\n",
    "                'index': p[1],\n",
    "                'Cosine': p[2],\n",
    "                'L1': p[3],\n",
    "                'L2': p[4],\n",
    "                'L-infinity': p[5],\n",
    "                'cfg': cfg,\n",
    "                'sampler': sampler,\n",
    "                'step': step,\n",
    "                'width': width,\n",
    "                'height': height,\n",
    "                'nsfw': nsfw,\n",
    "                'prompt': prompt\n",
    "            }\n",
    "            low_pairs.append(new_p)\n",
    "        \n",
    "    if p[distance_i] < HIGH_BAR:\n",
    "        break\n",
    "    \n",
    "print(HIGH_BAR, len(low_pairs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Images for Error Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a gausian distribution\n",
    "mean, std = norm.fit([p[distance_i] for p in distances])\n",
    "print(mean, std)\n",
    "\n",
    "HIGH_BAR = mean + 4 * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_pairs = []\n",
    "\n",
    "for p in sorted_pairs:\n",
    "    if p[distance_i] > HIGH_BAR:\n",
    "        cur_i = name_to_index[p[0]]\n",
    "        cfg = metadata_df['cfg'][cur_i]\n",
    "        sampler = metadata_df['sampler'][cur_i]\n",
    "        step = metadata_df['step'][cur_i]\n",
    "        nsfw = metadata_df['image_nsfw'][cur_i]\n",
    "        width = metadata_df['width'][cur_i]\n",
    "        height = metadata_df['height'][cur_i]\n",
    "        nsfw = metadata_df['image_nsfw'][cur_i]\n",
    "        prompt = metadata_df['prompt'][cur_i]\n",
    "        \n",
    "        if nsfw < 2 and abs(cfg - 7) < 5 and step == 50 and width == 512 and height == 512 and len(prompt) < 5 and sampler == 8 and '😂' in prompt:\n",
    "            new_p = {\n",
    "                'name': p[0],\n",
    "                'index': p[1],\n",
    "                'Cosine': p[2],\n",
    "                'L1': p[3],\n",
    "                'L2': p[4],\n",
    "                'L-infinity': p[5],\n",
    "                'cfg': cfg,\n",
    "                'sampler': sampler,\n",
    "                'step': step,\n",
    "                'width': width,\n",
    "                'height': height,\n",
    "                'nsfw': nsfw,\n",
    "                'prompt': prompt\n",
    "            }\n",
    "            low_pairs.append(new_p)\n",
    "        \n",
    "    if p[distance_i] < HIGH_BAR:\n",
    "        break\n",
    "    \n",
    "print(HIGH_BAR, len(low_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dsiplay these bad images\n",
    "folders = glob(\"/project/diffusiondb/images/*\")\n",
    "existing_part_ids = set(\n",
    "    [int(re.sub(r\".*part-(\\d+)\", r\"\\1\", f)) for f in folders if \"json\" not in f]\n",
    ")\n",
    "\n",
    "shutil.rmtree(join(WORKING_IMAGE_DIR, 'bad-images'))\n",
    "os.makedirs(join(WORKING_IMAGE_DIR, 'bad-images'))\n",
    "\n",
    "# Copy low distance images into one folder\n",
    "random_indexes = np.random.choice(len(low_pairs), len(low_pairs), replace=False)\n",
    "count_limit = 50\n",
    "visited_prompts = set()\n",
    "\n",
    "i = 0\n",
    "with tqdm(total=count_limit) as pbar:\n",
    "    while i < count_limit:\n",
    "        p = low_pairs[random_indexes[i]]\n",
    "\n",
    "        cur_path = get_image_path(name_to_part, p['name'], existing_part_ids)\n",
    "        local_path = join(WORKING_IMAGE_DIR, 'bad-images', basename(cur_path))\\\n",
    "\n",
    "        if not exists(local_path):\n",
    "            shutil.copyfile(cur_path, local_path)\n",
    "            \n",
    "        img = Image.open(local_path)\n",
    "        img.thumbnail((150, 150), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        prompt = p['prompt']\n",
    "        \n",
    "        # if prompt in visited_prompts:\n",
    "        #     i += 1\n",
    "        #     continue\n",
    "        # visited_prompts.add(prompt)\n",
    "        \n",
    "        display(img)\n",
    "        print(p)\n",
    "        i += 1\n",
    "\n",
    "        # try:\n",
    "        #     canvas = ImageDraw.Draw(img)\n",
    "        #     canvas.text((10, 5), prompt[:40], fill=(255, 0, 0))\n",
    "            \n",
    "        #     if len(prompt) > 40:\n",
    "        #         canvas.text((10, 15), prompt[40:80], fill=(255, 0, 0))\n",
    "                \n",
    "        #     i += 1\n",
    "        #     pbar.update(1)\n",
    "                \n",
    "        # except:\n",
    "        #     pass\n",
    "        \n",
    "        # img.save(local_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Bad Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts = set([p['prompt'] for p in low_pairs])\n",
    "# prompts = list(prompts)\n",
    "\n",
    "# md_string = ''\n",
    "# md_string += '|||\\n'\n",
    "# md_string += '|:---|:---|\\n'\n",
    "\n",
    "# i = 0\n",
    "# while i < len(prompts) - 1:\n",
    "#     md_string += f'|{prompts[i]}|{prompts[i + 1]}|\\n'\n",
    "#     i += 2\n",
    "\n",
    "# print(md_string[:10000])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to see the high-tfidf score words in bad prompts\n",
    "\n",
    "Not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "# from emoji import demojize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts = set([demojize(p['prompt']) for p in low_pairs])\n",
    "# prompts = list(prompts)\n",
    "\n",
    "# # model = CountVectorizer(ngram_range=(1, 2)).fit(prompts)\n",
    "# # words = model.transform(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_prompts = []\n",
    "# existing_prompts = set(prompts)\n",
    "\n",
    "# for p in tqdm(set(metadata_df['prompt'])):\n",
    "#     cur_p = demojize(p)\n",
    "#     if cur_p not in existing_prompts:\n",
    "#         all_prompts.append(cur_p)\n",
    "        \n",
    "# all_docs = list(all_prompts)\n",
    "# bad_prompt_doc = ' '.join(prompts)\n",
    "# all_docs.append(bad_prompt_doc)\n",
    "\n",
    "# count_model = CountVectorizer(ngram_range=(1, 2))\n",
    "# count = count_model.fit_transform(all_docs)\n",
    "\n",
    "# cout_copy = count.copy()\n",
    "# cout_copy[len(all_docs) - 1, :] = cout_copy[len(all_docs) - 1, :] / 10\n",
    "\n",
    "# tfidf_model = TfidfTransformer(use_idf=True)\n",
    "# tfidf = tfidf_model.fit_transform(cout_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_prompt_tfidf = tfidf[len(all_docs) - 1, :].todense()\n",
    "# bad_words = []\n",
    "\n",
    "# for i, name in enumerate(count_model.get_feature_names_out()):\n",
    "#     if bad_prompt_tfidf[0, i] > 0:\n",
    "#         bad_words.append([name, bad_prompt_tfidf[0, i]])\n",
    "\n",
    "# bad_words.sort(key=lambda x: x[1], reverse=True)\n",
    "# # bad_words[:200]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the word count in bad prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_low_pairs = []\n",
    "added_prompts = set()\n",
    "for p in low_pairs:\n",
    "    if p['prompt'] not in added_prompts:\n",
    "        added_prompts.add(p['prompt'])\n",
    "        unique_low_pairs.append(p)\n",
    "        \n",
    "len(unique_low_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_prompts = set([p['prompt'] for p in low_pairs])\n",
    "bad_promtps_length = [len(p) for p in bad_prompts]\n",
    "\n",
    "all_prompts = set(metadata_df['prompt'])\n",
    "all_prompts_length = [len(p) for p in all_prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, np.max(all_prompts_length), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.title('Prompt length distribution')\n",
    "plt.hist(bad_promtps_length, bins, alpha=0.5, label='bad', density=True)\n",
    "plt.hist(all_prompts_length, bins, alpha=0.5, label='all', density=True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the token length of bad prompts vs all prompts\n",
    "prompt_token_lengths = pickle.load(open('./outputs/token_count_truncated.pkl', 'rb'))\n",
    "prompt_token_lengths = prompt_token_lengths.numpy()\n",
    "\n",
    "prompt_to_index = {}\n",
    "\n",
    "for i in tqdm(range(len(prompts))):\n",
    "    prompt_to_index[prompts[i]] = i\n",
    "    \n",
    "bad_token_lengths = []\n",
    "\n",
    "for bp in tqdm(bad_prompts):\n",
    "    cur_i = prompt_to_index[bp]\n",
    "    bad_token_lengths.append(prompt_token_lengths[cur_i])\n",
    "    \n",
    "stats.ttest_ind(bad_token_lengths, prompt_token_lengths, equal_var=False, alternative='less')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Lang Distribution in Bad Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_en_prompts = pickle.load(open(\"./outputs/non-en-prompts.pkl\", \"rb\"))\n",
    "\n",
    "lang_counter = Counter(non_en_prompts.values())\n",
    "\n",
    "lang_counter_map = {'en': 0}\n",
    "lang_counter_list = [(len(prompts) - len(non_en_prompts)) / len(prompts)]\n",
    "\n",
    "cur_i = 1\n",
    "for lang in lang_counter:\n",
    "    lang_counter_map[lang] = cur_i\n",
    "    lang_counter_list.append(lang_counter[lang] / len(prompts))\n",
    "    cur_i += 1\n",
    "    \n",
    "lang_counter_list = np.array(lang_counter_list)\n",
    "np.sum(lang_counter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_lang_counter = {}\n",
    "\n",
    "for bp in bad_prompts:\n",
    "    if bp in non_en_prompts:\n",
    "        lang = non_en_prompts[bp]\n",
    "        if lang in bad_lang_counter:\n",
    "            bad_lang_counter[lang] += 1\n",
    "        else:\n",
    "            bad_lang_counter[lang] = 1\n",
    "\n",
    "bad_lang_counter_list = np.zeros(len(lang_counter_list))\n",
    "bad_lang_counter_list[0] = (\n",
    "    len(bad_prompts) - np.sum(list(bad_lang_counter.values()))\n",
    ") / len(bad_prompts)\n",
    "\n",
    "for lang in bad_lang_counter:\n",
    "    cur_i = lang_counter_map[lang]\n",
    "    bad_lang_counter_list[cur_i] = bad_lang_counter[lang] / len(bad_prompts)\n",
    "\n",
    "np.sum(bad_lang_counter_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = stats.chisquare(\n",
    "    f_obs=[991, 160],\n",
    "    f_exp=[1131.4214483066346, 19.578551693365398]\n",
    ")\n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check CFG Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_cfgs = [p['cfg'] for p in unique_low_pairs if p['cfg']< 200]\n",
    "plt.hist(bad_cfgs, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the language in bad prompts\n",
    "non_en_prompts = pickle.load(open(\"./outputs/non-en-prompts.pkl\", \"rb\"))\n",
    "\n",
    "bad_prompt_lang = {}\n",
    "\n",
    "for p in bad_prompts:\n",
    "    if p in non_en_prompts:\n",
    "        bad_prompt_lang[p] = non_en_prompts[p]\n",
    "        \n",
    "len(bad_prompt_lang) / len(bad_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dsiplay these bad images\n",
    "folders = glob(\"/project/diffusiondb/images/*\")\n",
    "existing_part_ids = set(\n",
    "    [int(re.sub(r\".*part-(\\d+)\", r\"\\1\", f)) for f in folders if \"json\" not in f]\n",
    ")\n",
    "\n",
    "shutil.rmtree(join(WORKING_IMAGE_DIR, 'bad-images'))\n",
    "os.makedirs(join(WORKING_IMAGE_DIR, 'bad-images'))\n",
    "\n",
    "# Copy low distance images into one folder\n",
    "random_indexes = np.random.choice(len(low_pairs), len(low_pairs), replace=False)\n",
    "count_limit = 10\n",
    "visited_prompts = set()\n",
    "\n",
    "i = 0\n",
    "with tqdm(total=count_limit) as pbar:\n",
    "    while i < count_limit:\n",
    "        p = low_pairs[random_indexes[i]]\n",
    "        \n",
    "        if p['cfg'] != 7 or len(p['prompt']) < 30:\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        cur_path = get_image_path(name_to_part, p['name'], existing_part_ids)\n",
    "        local_path = join(WORKING_IMAGE_DIR, 'bad-images', basename(cur_path))\\\n",
    "\n",
    "        if not exists(local_path):\n",
    "            shutil.copyfile(cur_path, local_path)\n",
    "            \n",
    "        img = Image.open(local_path)\n",
    "        img.thumbnail((300, 300), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        prompt = p['prompt']\n",
    "        \n",
    "        if prompt in visited_prompts:\n",
    "            continue\n",
    "        visited_prompts.add(prompt)\n",
    "        \n",
    "        display(img)\n",
    "        print(p)\n",
    "        i += 1\n",
    "\n",
    "        # try:\n",
    "        #     canvas = ImageDraw.Draw(img)\n",
    "        #     canvas.text((10, 5), prompt[:40], fill=(255, 0, 0))\n",
    "            \n",
    "        #     if len(prompt) > 40:\n",
    "        #         canvas.text((10, 15), prompt[40:80], fill=(255, 0, 0))\n",
    "                \n",
    "        #     i += 1\n",
    "        #     pbar.update(1)\n",
    "                \n",
    "        # except:\n",
    "        #     pass\n",
    "        \n",
    "        # img.save(local_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy Analyais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to compute many stats at once\n",
    "\n",
    "from skimage.measure.entropy import shannon_entropy\n",
    "\n",
    "img = Image.open(join(WORKING_IMAGE_DIR, 'bad-images', '415bf54a-ebe1-4e0a-ae5d-ef0b7c571b15.webp'))\n",
    "img_mat = np.array(img)\n",
    "\n",
    "shannon_entropy(img_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_pairs = []\n",
    "for f in glob(join(WORKING_IMAGE_DIR, 'bad-images', '*.webp')):\n",
    "    img = Image.open(f)\n",
    "    img_mat = np.array(img)\n",
    "\n",
    "    entropy_pairs.append([img, shannon_entropy(img_mat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_pairs = sorted(entropy_pairs, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in entropy_pairs[:10]:\n",
    "#     display(p[0])\n",
    "#     print(p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.load(open('./entropy-pickles/entropy-000001.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same Prompt Different Image\n",
    "\n",
    "We try to identify prompts that generate very different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_parquet(PARQUET_PATH, columns=['image_name', 'part_id', 'prompt'])\n",
    "print(metadata_df.shape)\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob(\"/project/diffusiondb/images/*\")\n",
    "existing_part_ids = set(\n",
    "    [int(re.sub(r\".*part-(\\d+)\", r\"\\1\", f)) for f in folders if \"json\" not in f]\n",
    ")\n",
    "\n",
    "def get_image_path(part_id, name, existing_part_ids):\n",
    "    \"\"\"\n",
    "    Get the path of an image by its name.\n",
    "    \"\"\"\n",
    "    \n",
    "    if part_id in existing_part_ids:\n",
    "        image_path = join(REMOTE_IMAGE_DIR, f'part-{part_id:06}', name)\n",
    "        return image_path\n",
    "    \n",
    "    # Need to download the image's zip file first\n",
    "    else:\n",
    "        cur_zip = join(WORK_DIR, f\"part-{part_id:06}.zip\")\n",
    "        cur_img_dir = join(WORKING_IMAGE_DIR, f\"part-{part_id:06}\")\n",
    "\n",
    "        if not exists(cur_img_dir):\n",
    "            # Download and extract the zip file\n",
    "            if part_id > 100000:\n",
    "                shutil.copyfile(\n",
    "                    join(ZIP_DIR2, f\"part-{part_id:06}.zip\"),\n",
    "                    cur_zip,\n",
    "                )\n",
    "            else:\n",
    "                shutil.copyfile(\n",
    "                    join(ZIP_DIR1, f\"part-{part_id:06}.zip\"),\n",
    "                    cur_zip,\n",
    "                )\n",
    "\n",
    "            shutil.unpack_archive(cur_zip, cur_img_dir)\n",
    "            \n",
    "        image_path = join(WORKING_IMAGE_DIR, f'part-{part_id:06}', name)\n",
    "        \n",
    "    \n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt -> [(image_name, part_id)]\n",
    "prompt_to_images = {}\n",
    "\n",
    "for row in tqdm(metadata_df.itertuples(), total=metadata_df.shape[0]):\n",
    "    i = row[0]\n",
    "    name = row[1]\n",
    "    part_id = row[2]\n",
    "    prompt = row[3].lower()\n",
    "    \n",
    "    if prompt in prompt_to_images:\n",
    "        prompt_to_images[prompt].append((name, part_id))\n",
    "    else:\n",
    "        prompt_to_images[prompt] = [(name, part_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep prompts with more than 3 occurance\n",
    "filtered_prompt_to_images = {}\n",
    "\n",
    "for p in tqdm(prompt_to_images):\n",
    "    if len(prompt_to_images[p]) > 3:\n",
    "        filtered_prompt_to_images[p] = prompt_to_images[p]\n",
    "        \n",
    "print(len(filtered_prompt_to_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(prompt_to_images, open('./outputs/prompt_to_images.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most-used prompts\n",
    "prompt_to_images = pickle.load(open('./outputs/prompt_to_images.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_image_count_pairs = []\n",
    "\n",
    "for p in tqdm(prompt_to_images):\n",
    "    prompt_image_count_pairs.append([p, len(prompt_to_images[p])])\n",
    "    \n",
    "prompt_image_count_pairs.sort(key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_to_images\n",
    "plt.title('Prompt Count (top 2000)')\n",
    "plt.bar(list(range(len(prompt_image_count_pairs[:2000]))), [p[1] for p in prompt_image_count_pairs[:2000]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_image_count_pairs[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_max_distance = {}\n",
    "\n",
    "# last_part_id = -1\n",
    "# last_image_names = None\n",
    "# last_image_emb = None\n",
    "# last_image_names_to_id = None\n",
    "\n",
    "# for p in tqdm(filtered_prompt_to_images):\n",
    "    \n",
    "#     local_embs = []\n",
    "#     max_distance = -np.inf\n",
    "#     min_distance = np.inf\n",
    "    \n",
    "#     for name, part_id in filtered_prompt_to_images[p]:\n",
    "        \n",
    "#         if part_id != last_part_id:\n",
    "#             image_emb_data = np.load(join(IMAGE_EMB_DIR, f'part-{part_id:06}-image-emb.npz'))\n",
    "\n",
    "#             last_image_names = image_emb_data['images_name']\n",
    "#             last_image_names_to_id = {}\n",
    "#             for i, name in enumerate(last_image_names):\n",
    "#                 last_image_names_to_id[name] = i\n",
    "\n",
    "#             last_image_emb = image_emb_data['images_emb']\n",
    "#             last_part_id = part_id\n",
    "        \n",
    "#         cur_i = last_image_names_to_id[name]\n",
    "#         local_embs.append(last_image_emb[cur_i, :])\n",
    "    \n",
    "#     # Comptue pair-wise cosine distance\n",
    "#     for i in range(len(local_embs)):\n",
    "#         for j in range(i + 1, len(local_embs)):\n",
    "#             cur_d = cosine(local_embs[i], local_embs[j])\n",
    "            \n",
    "#             if cur_d > max_distance:\n",
    "#                 max_distance = cur_d\n",
    "                \n",
    "#             if cur_d < min_distance:\n",
    "#                 min_distance = cur_d\n",
    "                \n",
    "#     emb_mean = np.mean(local_embs, axis=0)\n",
    "#     emb_std = np.std(local_embs, axis=0)\n",
    "    \n",
    "#     record = {\n",
    "#         'min_distance': min_distance,\n",
    "#         'max_distance': max_distance,\n",
    "#         'count': len(local_embs),\n",
    "#         'images': filtered_prompt_to_images[p]\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very different images from the same prompt\n",
    "\n",
    "cur_distance = pickle.load(open('./outputs/distance-0-100000.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spacy_fastlang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_parquet(\n",
    "    PARQUET_PATH,\n",
    "    columns=[\n",
    "        \"image_name\",\n",
    "        \"part_id\",\n",
    "        \"prompt\",\n",
    "        \"cfg\",\n",
    "        \"step\",\n",
    "        \"sampler\",\n",
    "        \"width\",\n",
    "        \"height\",\n",
    "        \"image_nsfw\",\n",
    "    ],\n",
    ")\n",
    "print(metadata_df.shape)\n",
    "metadata_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_prompts = list(set(metadata_df['prompt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"language_detector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_en_prompts = {}\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp.add_pipe(\"language_detector\")\n",
    "\n",
    "# for p in tqdm(unique_prompts):\n",
    "#     doc = nlp(p)\n",
    "#     if doc._.language != 'en':\n",
    "#         non_en_prompts[p] = doc._.language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_en_prompts = pickle.load(open(\"./outputs/non-en-prompts.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = non_en_prompts.values()\n",
    "\n",
    "counter = Counter(langs)\n",
    "\n",
    "pairs = list(zip(counter.keys(), counter.values()))\n",
    "pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "plt.figure(figsize=(18, 4))\n",
    "plt.bar([p[0] for p in pairs], [p[1] for p in pairs])\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title('Non-English Prompt Language Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(non_en_prompts))\n",
    "print(len(counter))\n",
    "\n",
    "lang_count = 0\n",
    "for c in counter:\n",
    "    if counter[c] > 100:\n",
    "        lang_count += 1\n",
    "lang_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auth_token = os.environ[\"HFTOKEN\"]\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = np.array(list(set(metadata_df['prompt'])))\n",
    "len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_tok_length(text_inputs):\n",
    "    \"\"\"Calculate average number of tokens in input\"\"\"\n",
    "    n_tokens = text_inputs[\"attention_mask\"].sum(-1) - 2 # remove BOS and EOS added tags\n",
    "    return n_tokens\n",
    "\n",
    "\n",
    "# !! Long running cell. Choose batch size that computer can handle easily\n",
    "bs = 10000\n",
    "i = 0\n",
    "vocab_size = pipe.tokenizer.vocab_size\n",
    "total_token_length = torch.zeros(len(prompts), dtype=torch.int16)\n",
    "total_iter = len(prompts) // bs + 1\n",
    "nprompts = len(prompts)\n",
    "n = 0\n",
    "with tqdm(total=total_iter) as pbar:\n",
    "    while i < nprompts:\n",
    "        n+= 1\n",
    "        pbar.update(1)\n",
    "        pidxs = slice(i, i+bs)\n",
    "        p = prompts[pidxs].tolist()\n",
    "        text_inputs = pipe.tokenizer(\n",
    "            p,\n",
    "            padding=True,\n",
    "            max_length=pipe.tokenizer.model_max_length,\n",
    "            truncation=False,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        length = batch_tok_length(text_inputs)\n",
    "        total_token_length[pidxs] = length\n",
    "\n",
    "        i += bs\n",
    "\n",
    "        if n == total_iter:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the token counts\n",
    "token_count_dict = {}\n",
    "for i in range(len(total_token_length)):\n",
    "    token_count_dict[prompts[i]] = total_token_length[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(total_token_length, open('./outputs/token_count_truncated.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncated_total_token_length = pickle.load(open('./outputs/token_count_truncated.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.grid(alpha=0.2)\n",
    "n = n.astype(\"int\")\n",
    "n, bins, patches = plt.hist(np.array(truncated_total_token_length),\n",
    "                            bins=37, edgecolor='white', linewidth=0.5, alpha=0.9)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel(\"Number of tokens in prompt\", fontsize=16)\n",
    "plt.title(\"Distribution of Prompt Length (# of Tokens)\", fontsize=18)\n",
    "# plt.savefig(\"plots/token_length_dist.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins[-2] - bins[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(total_token_length, open('./outputs/token_count_no_truncated.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_token_length = pickle.load(open('./outputs/token_count_no_truncated.pkl', 'rb'))\n",
    "total_token_length = total_token_length.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.grid(alpha=0.2)\n",
    "\n",
    "# cur_lengths = [l for l in total_token_length if l > 70 and l < 140]\n",
    "# n, bins, patches = plt.hist(cur_lengths, bins=40, edgecolor='white', linewidth=0.5, alpha=0.9)\n",
    "# plt.xticks(fontsize=20)\n",
    "# plt.yticks(fontsize=20)\n",
    "# plt.xlabel(\"Number of tokens in prompt\", fontsize=16)\n",
    "# plt.title(\"Distribution of Prompt Length (# of Tokens)\", fontsize=18)\n",
    "# plt.savefig(\"plots/token_length_dist_untrunc.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify examples in the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_parquet(\n",
    "    PARQUET_PATH,\n",
    ")\n",
    "print(metadata_df.shape)\n",
    "metadata_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows = []\n",
    "\n",
    "for row in tqdm(metadata_df.itertuples(), total=len(metadata_df)):\n",
    "    # if 'old couple smiling' in row[2].lower():\n",
    "    if 'watercolor painting' in row[2].lower() and row[6] > 7 and len(row[2]) < 120:\n",
    "    # if 'fighting russian' in row[2].lower():\n",
    "        selected_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(selected_rows))\n",
    "selected_rows[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob(\"/project/diffusiondb/images/*\")\n",
    "existing_part_ids = set(\n",
    "    [int(re.sub(r\".*part-(\\d+)\", r\"\\1\", f)) for f in folders if \"json\" not in f]\n",
    ")\n",
    "\n",
    "def get_image_path(part_id, name, existing_part_ids):\n",
    "    \"\"\"\n",
    "    Get the path of an image by its name.\n",
    "    \"\"\"\n",
    "    \n",
    "    if part_id in existing_part_ids:\n",
    "        image_path = join(REMOTE_IMAGE_DIR, f'part-{part_id:06}', name)\n",
    "        return image_path\n",
    "    \n",
    "    # Need to download the image's zip file first\n",
    "    else:\n",
    "        cur_zip = join(WORK_DIR, f\"part-{part_id:06}.zip\")\n",
    "        cur_img_dir = join(WORKING_IMAGE_DIR, f\"part-{part_id:06}\")\n",
    "\n",
    "        if not exists(cur_img_dir):\n",
    "            # Download and extract the zip file\n",
    "            if part_id > 100000:\n",
    "                shutil.copyfile(\n",
    "                    join(ZIP_DIR2, f\"part-{part_id:06}.zip\"),\n",
    "                    cur_zip,\n",
    "                )\n",
    "            else:\n",
    "                shutil.copyfile(\n",
    "                    join(ZIP_DIR1, f\"part-{part_id:06}.zip\"),\n",
    "                    cur_zip,\n",
    "                )\n",
    "\n",
    "            shutil.unpack_archive(cur_zip, cur_img_dir)\n",
    "            \n",
    "        image_path = join(WORKING_IMAGE_DIR, f'part-{part_id:06}', name)\n",
    "        \n",
    "    \n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dsiplay these bad images\n",
    "folders = glob(\"/project/diffusiondb/images/*\")\n",
    "existing_part_ids = set(\n",
    "    [int(re.sub(r\".*part-(\\d+)\", r\"\\1\", f)) for f in folders if \"json\" not in f]\n",
    ")\n",
    "\n",
    "shutil.rmtree(join(WORKING_IMAGE_DIR, 'bad-images'))\n",
    "os.makedirs(join(WORKING_IMAGE_DIR, 'bad-images'))\n",
    "\n",
    "i = 165\n",
    "count_limit = 175\n",
    "\n",
    "with tqdm(total=count_limit) as pbar:\n",
    "    while i < min(count_limit, len(selected_rows)):\n",
    "        p = selected_rows[i]\n",
    "\n",
    "        cur_path = get_image_path(p[3], p[1], existing_part_ids)\n",
    "        local_path = join(WORKING_IMAGE_DIR, 'bad-images', basename(cur_path))\\\n",
    "\n",
    "        if not exists(local_path):\n",
    "            shutil.copyfile(cur_path, local_path)\n",
    "            \n",
    "        img = Image.open(local_path)\n",
    "        img.thumbnail((145, 145), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        prompt = p[3]\n",
    "        \n",
    "        display(img)\n",
    "        print(p)\n",
    "        i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9758838403ef5c64e3388c7f7eb0622abdec8769e35829ff20981977cccefff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
